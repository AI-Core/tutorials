{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchtext tutorial\n",
    "\n",
    "\n",
    "Made by [Andrea Sottana](http://github.com/AndreaSottana) and adapted from the following [tutorial](https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/)\n",
    "\n",
    "This notebook shows how you can use your own custom dataset starting from the raw form (for example a .csv file) with the `torch` library, to easily do some cleaning and preprocessing (such as tokenization), build a vocabulary, and ultimately create an `Iterator` or `BucketIterator` object that you can feed it into a neural network built using the `torch` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset, Iterator, BucketIterator\n",
    "from torchtext import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=20)  # shows info level loggings (we'll use this to print the loss during training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: multi-class classification, single label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data `Field` specifies how you want a certain field to be processed, for example whether you want to tokenize it, lower case the text etc. In our case we have one text field, and one label field for the sentiment analysis, which we represent with an integer, where 0 is negative, 1 is neutral and 2 is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, tokenize='spacy', lower=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>numerical_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8539</th>\n",
       "      <td>A real snooze .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8540</th>\n",
       "      <td>No surprises .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8541</th>\n",
       "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8542</th>\n",
       "      <td>Her fans walked out muttering words like `` ho...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8543</th>\n",
       "      <td>In this case zero .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8544 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    labels  \\\n",
       "0     The Rock is destined to be the 21st Century 's...  positive   \n",
       "1     The gorgeously elaborate continuation of `` Th...  positive   \n",
       "2     Singer\\/composer Bryan Adams contributes a sle...  positive   \n",
       "3     You 'd think by now America would have had eno...   neutral   \n",
       "4                  Yet the act is still charming here .  positive   \n",
       "...                                                 ...       ...   \n",
       "8539                                    A real snooze .  negative   \n",
       "8540                                     No surprises .  negative   \n",
       "8541  We 've seen the hippie-turned-yuppie plot befo...  positive   \n",
       "8542  Her fans walked out muttering words like `` ho...  negative   \n",
       "8543                                In this case zero .  negative   \n",
       "\n",
       "      numerical_labels  \n",
       "0                    2  \n",
       "1                    2  \n",
       "2                    2  \n",
       "3                    1  \n",
       "4                    2  \n",
       "...                ...  \n",
       "8539                 0  \n",
       "8540                 0  \n",
       "8541                 2  \n",
       "8542                 0  \n",
       "8543                 0  \n",
       "\n",
       "[8544 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember to source the .envrc file in the terminal before launching this notebook to \n",
    "# ensure it can use the environment variables correctly.\n",
    "\n",
    "folder = os.path.join(os.getenv('DATA_DIR'), 'movie_review_dataset')\n",
    "train_dataset = pd.read_csv(os.path.join(folder, 'train_dataset.csv'))\n",
    "valid_dataset = pd.read_csv(os.path.join(folder, 'valid_dataset.csv'))\n",
    "test_dataset = pd.read_csv(os.path.join(folder, 'test_dataset.csv'))\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells the field what data to work on. Note that the fields we pass in must be in the same order as the columns in our csv file. For the columns we don't use, we pass in a tuple where the field element is None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text', <torchtext.data.field.Field at 0x125468d90>),\n",
       " ('labels', None),\n",
       " ('numerical_labels', <torchtext.data.field.Field at 0x101859610>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = [(\"text\", TEXT), (\"labels\", None), (\"numerical_labels\", LABEL)]\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TabularDataset` is one of the built-in Datasets in torchtext that handle common data formats; this one is good for .csv files. Other datasets, such as `LanguageModelingDataset` or `TranslationDataset`, are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = TabularDataset.splits(\n",
    "    path = folder,\n",
    "    train = 'train_dataset.csv',\n",
    "    validation = 'valid_dataset.csv',\n",
    "    test = 'test_dataset.csv',\n",
    "    format = 'csv',\n",
    "    skip_header = True,\n",
    "    fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.example.Example object at 0x12a185950> \n",
      "\n",
      "{'text': ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '`', '`', 'conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean', '-', 'claud', 'van', 'damme', 'or', 'steven', 'segal', '.'], 'numerical_labels': '2'} \n",
      "\n",
      "dict_keys(['text', 'numerical_labels']) \n",
      "\n",
      "['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '`', '`', 'conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean', '-', 'claud', 'van', 'damme', 'or', 'steven', 'segal', '.']\n"
     ]
    }
   ],
   "source": [
    "print(train[0], '\\n')\n",
    "\n",
    "# This is an Example object. The Example object bundles the attributes of a single data \n",
    "# point together. We also see that the text has already been tokenized for us, but has \n",
    "# not yet been converted to integers. \n",
    "\n",
    "print(train[0].__dict__, '\\n')\n",
    "print(train[0].__dict__.keys(), '\\n')\n",
    "print(train[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is constructing the mapping from words to ids. The vocabulary is normally built on the training set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torchtext has its own class called Vocab for handling the vocabulary. The Vocab class holds a mapping from word to id in its `stoi` attribute and a reverse mapping in its `itos` attribute. Words that are not included in the vocabulary will be converted into `<unk>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[12])\n",
    "print(TEXT.vocab.stoi['it'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create an Iterator to pass the data to our model.  \n",
    "\n",
    "In torchvision and PyTorch, the processing and batching of data is handled by DataLoaders. For some reason, torchtext has renamed the objects that do the exact same thing to Iterators. The basic functionality is the same, but Iterators, as we will see, have some convenient functionality that is unique to NLP.  \n",
    "\n",
    "We also need to tell the BucketIterator what attribute you want to bucket the data on. In our case, we want to bucket based on the lengths of the comment_text field, so we pass that in as a keyword argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iter, valid_iter, test_iter = BucketIterator.splits(\n",
    "    (train, valid, test),\n",
    "    batch_sizes=(64, 64, 64),\n",
    "    device=device,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    sort_within_batch=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative would be to use a standard iterator for the test set, given we do not need to shuffle the data since we'll be outputting the predictions at the end of training.  \n",
    "The code would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter = BucketIterator.splits(\n",
    "    (train, valid),\n",
    "    batch_sizes=(64, 64),\n",
    "    device=device,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    sort_within_batch=True\n",
    ")\n",
    "\n",
    "test_iter = Iterator(\n",
    "    test, batch_size=64, device=device, sort=False, sort_within_batch=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what a `BucketIterator` looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.iterator.BucketIterator'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 64]\n",
       "\t[.text]:[torch.LongTensor of size 13x64]\n",
       "\t[.numerical_labels]:[torch.LongTensor of size 64]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train_iter))\n",
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = list(train_iter)\n",
    "valid_dataloader = list(valid_iter)\n",
    "test_dataloader = list(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 64]), torch.Size([64]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = train_dataloader[0]\n",
    "it.text.shape, it.numerical_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'dataset': <torchtext.data.dataset.TabularDataset at 0x132a07f10>,\n",
       " 'fields': dict_keys(['text', 'labels', 'numerical_labels']),\n",
       " 'input_fields': ['text', 'numerical_labels'],\n",
       " 'target_fields': [],\n",
       " 'text': tensor([[  108,     3,  2361,  ...,     5,     3,  2139],\n",
       "         [    3,    52,     2,  ..., 11259,   109,  2284],\n",
       "         [  724,     6,     1,  ...,     4,   645,     4],\n",
       "         ...,\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1],\n",
       "         [    1,     1,     1,  ...,     1,     1,     1]]),\n",
       " 'numerical_labels': tensor([0, 0, 1, 0, 2, 2, 1, 2, 0, 0, 2, 1, 1, 0, 2, 2, 0, 2, 2, 2, 0, 0, 1, 2,\n",
       "         2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 1, 0, 1, 2, 0, 0, 0, 2, 2,\n",
       "         1, 1, 2, 0, 1, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 0])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(list(test_iter)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "<class 'list'>\n",
      "[\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 8x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 28x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 17x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 32x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 27x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 32x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 22x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 23x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 33x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 25x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 38x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 19x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 31x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 29x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 37x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 20x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 7x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 10x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 41x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 20x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 35x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 9x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 40x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 34x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 29x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 14x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 12x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 23x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 6x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 25x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 13x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 19x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 36x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 8x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 21x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 53x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 17x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 21x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 44x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 31x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 7x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 14x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 20x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 25x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 16x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 9x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 4x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 15x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 26x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 21x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 24x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 14x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 20x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 18x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 10x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 22x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 6x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 17x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 27x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 21x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 12x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 13x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 28x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 14x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 26x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 8x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 15x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 18x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 30x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 10x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 15x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 15x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 3x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 27x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 12x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 22x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 16x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 11x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 16x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 11x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 34x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 29x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 30x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 24x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 24x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 16x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 9x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 13x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 4x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 11x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 19x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 18x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 11x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 18x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 26x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 24x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 5x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 19x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 6x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 23x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 31x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 16x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 32]\n",
      "\t[.text]:[torch.LongTensor of size 53x32]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 32], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 18x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 33x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 11x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 24x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 17x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 13x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 15x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 44x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 23x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 37x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 25x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 19x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 9x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 15x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 20x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 21x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 12x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 5x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 27x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 34x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 10x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 28x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 26x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 6x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 17x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 22x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 7x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 20x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 29x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 8x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64], \n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.text]:[torch.LongTensor of size 14x64]\n",
      "\t[.numerical_labels]:[torch.LongTensor of size 64]]\n"
     ]
    }
   ],
   "source": [
    "iterator = train_dataloader\n",
    "print(len(list(iterator)))\n",
    "print(type(list(iterator)))\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "<class 'torchtext.data.batch.Batch'>\n",
      "torch.Size([39, 64]) torch.Size([64])\n",
      "tensor([[    3,   518,    24,  ...,     3,     5,     3],\n",
      "        [   17,    14,   117,  ...,   312,  3186,   451],\n",
      "        [  526,  5411,    44,  ...,    83,     4,  5851],\n",
      "        ...,\n",
      "        [  954,  6992,     8,  ...,    66,  3110,  4645],\n",
      "        [12982, 15211,   225,  ...,     2,     2,     2],\n",
      "        [    2,     2,     2,  ...,     1,     1,     1]]) tensor([2, 2, 1, 2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 2, 0, 0, 2, 2, 0, 1, 1, 0, 2, 2,\n",
      "        1, 0, 1, 0, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2,\n",
      "        0, 2, 2, 0, 0, 0, 1, 2, 2, 2, 0, 2, 1, 2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = list(train_iter)\n",
    "next_ = train_dataloader[0]\n",
    "print(len(next_))\n",
    "print(type(next_))\n",
    "print(next_.text.shape, next_.numerical_labels.shape)\n",
    "print(next_.text, next_.numerical_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is, finally, our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMultiClass(nn.Module):\n",
    "    def __init__(self, vocab_length, hidden_dim, emb_dim=300, num_lstm_layers=1, num_linear_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_length, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers=num_lstm_layers)\n",
    "        self.linear_layers = nn.ModuleList()\n",
    "        self.linear_layers = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_linear_layers)]\n",
    "        )\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.predictor = nn.Linear(hidden_dim, 3)  # 3 possible outcomes: negative, neutral, positive\n",
    "\n",
    "    def forward(self, seq):\n",
    "        emb = self.embedding(seq)\n",
    "        all_hidden, (h_n, c_n) = self.lstm(emb)\n",
    "        feature = h_n.squeeze() # taking the last output from the LSTM (we're dealing with many-to-one problem)\n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature)\n",
    "            feature = self.tanh(feature)\n",
    "         \n",
    "        preds = self.predictor(feature)\n",
    "        return preds\n",
    "\n",
    "\n",
    "model = LSTMultiClass(vocab_length=len(TEXT.vocab), hidden_dim=500, emb_dim=100, num_linear_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:43<00:00,  3.07it/s]\n",
      "INFO:__main__:Epoch: 1, Training Loss: 0.4198, Validation Loss: 0.4664\n",
      "100%|██████████| 134/134 [01:01<00:00,  2.19it/s]\n",
      "INFO:__main__:Epoch: 2, Training Loss: 0.3752, Validation Loss: 0.4840\n",
      "100%|██████████| 134/134 [00:52<00:00,  2.54it/s]\n",
      "INFO:__main__:Epoch: 3, Training Loss: 0.3788, Validation Loss: 0.4813\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "epochs = 3\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    model.train() # turn on training mode\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        x = batch.text  # independent variable (the input to the model)\n",
    "        y = batch.numerical_labels.long()  # dependent variable (the supervision data)\n",
    "        opt.zero_grad()\n",
    "        predictions = model(x)\n",
    "        loss = loss_func(predictions, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.data * x.size(0)\n",
    "    epoch_loss = running_loss / len(train)\n",
    "\n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            x = batch.text\n",
    "            y = batch.numerical_labels.long()\n",
    "            predictions = model(x)\n",
    "            loss = loss_func(predictions, y)\n",
    "            val_loss += loss.data * x.size(0)\n",
    "\n",
    "    val_loss /= len(valid)\n",
    "    logger.info('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: binary classification, multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>\"\\n\\nHello Marcruhwedell, and Welcome to Wikip...</td>\n",
       "      <td>0d39d2eaa40a6241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>...that's why I did ....cheers,   (talk · cont...</td>\n",
       "      <td>0d3b57f3b2db3f03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>No, it's not a delayed reaction\\n\\nI just happ...</td>\n",
       "      <td>0d3bb1f12d90a6a2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>\"\\n\\nA slight difference with you\\nI have to d...</td>\n",
       "      <td>0d3be13abf1bec52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>\"\\n\\nNonsense.  The truth is NO schools give s...</td>\n",
       "      <td>0d3c720db297b5a3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text                id  \\\n",
       "0     Explanation\\nWhy the edits made under my usern...  0000997932d777bf   \n",
       "1     D'aww! He matches this background colour I'm s...  000103f0d9cfb60f   \n",
       "2     Hey man, I'm really not trying to edit war. It...  000113f07ec002fd   \n",
       "3     \"\\nMore\\nI can't make any real suggestions on ...  0001b41b1c6bb37e   \n",
       "4     You, sir, are my hero. Any chance you remember...  0001d958c54c6e35   \n",
       "...                                                 ...               ...   \n",
       "4995  \"\\n\\nHello Marcruhwedell, and Welcome to Wikip...  0d39d2eaa40a6241   \n",
       "4996  ...that's why I did ....cheers,   (talk · cont...  0d3b57f3b2db3f03   \n",
       "4997  No, it's not a delayed reaction\\n\\nI just happ...  0d3bb1f12d90a6a2   \n",
       "4998  \"\\n\\nA slight difference with you\\nI have to d...  0d3be13abf1bec52   \n",
       "4999  \"\\n\\nNonsense.  The truth is NO schools give s...  0d3c720db297b5a3   \n",
       "\n",
       "      toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0         0             0        0       0       0              0  \n",
       "1         0             0        0       0       0              0  \n",
       "2         0             0        0       0       0              0  \n",
       "3         0             0        0       0       0              0  \n",
       "4         0             0        0       0       0              0  \n",
       "...     ...           ...      ...     ...     ...            ...  \n",
       "4995      0             0        0       0       0              0  \n",
       "4996      0             0        0       0       0              0  \n",
       "4997      1             0        0       0       1              0  \n",
       "4998      0             0        0       0       0              0  \n",
       "4999      0             0        0       0       0              0  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = os.path.join(os.getenv('DATA_DIR'), 'toxic_comments_dataset')\n",
    "train_dataset = pd.read_csv(os.path.join(folder, 'train_dataset.csv'))\n",
    "valid_dataset = pd.read_csv(os.path.join(folder, 'valid_dataset.csv'))\n",
    "test_dataset = pd.read_csv(os.path.join(folder, 'test_dataset.csv'))\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, tokenize='spacy', lower=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('comment_text', <torchtext.data.field.Field at 0x1332cf8d0>),\n",
       " ('id', None),\n",
       " ('toxic', <torchtext.data.field.Field at 0x134cc16d0>),\n",
       " ('severe_toxic', <torchtext.data.field.Field at 0x134cc16d0>),\n",
       " ('obscene', <torchtext.data.field.Field at 0x134cc16d0>),\n",
       " ('threat', <torchtext.data.field.Field at 0x134cc16d0>),\n",
       " ('insult', <torchtext.data.field.Field at 0x134cc16d0>),\n",
       " ('identity_hate', <torchtext.data.field.Field at 0x134cc16d0>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = [\n",
    "    (\"comment_text\", TEXT),\n",
    "    (\"id\", None),  \n",
    "    (\"toxic\", LABEL), \n",
    "    (\"severe_toxic\", LABEL),\n",
    "    (\"obscene\", LABEL),\n",
    "    (\"threat\", LABEL),\n",
    "    (\"insult\", LABEL),\n",
    "    (\"identity_hate\", LABEL)\n",
    "]\n",
    "\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = TabularDataset.splits(\n",
    "    path = folder,\n",
    "    train = 'train_dataset.csv',\n",
    "    validation = 'valid_dataset.csv',\n",
    "    test = 'test_dataset.csv',\n",
    "    format = 'csv',\n",
    "    skip_header = True,\n",
    "    fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iter, valid_iter, test_iter = BucketIterator.splits(\n",
    "    (train, valid, test),\n",
    "    batch_sizes=(64, 64, 64),\n",
    "    device=device,\n",
    "    sort_key=lambda x: len(x.comment_text),\n",
    "    sort_within_batch=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'dataset': <torchtext.data.dataset.TabularDataset at 0x1332cf9d0>,\n",
       " 'fields': dict_keys(['comment_text', 'id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']),\n",
       " 'input_fields': ['comment_text',\n",
       "  'toxic',\n",
       "  'severe_toxic',\n",
       "  'obscene',\n",
       "  'threat',\n",
       "  'insult',\n",
       "  'identity_hate'],\n",
       " 'target_fields': [],\n",
       " 'comment_text': tensor([[   5, 2497,   19,  ...,   13,  470,  642],\n",
       "         [  83,  926,   40,  ...,   12,   17,   32],\n",
       "         [  44,  178,  255,  ...,  336,   19,   31],\n",
       "         ...,\n",
       "         [   2,    0,  459,  ...,    2,  477,   32],\n",
       "         [  56,  123, 1150,  ..., 9944,   32,   31],\n",
       "         [   5,    2,    2,  ...,    1,    1,    1]]),\n",
       " 'toxic': tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'severe_toxic': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'obscene': tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'threat': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'insult': tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'identity_hate': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(list(train_iter)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = list(train_iter)\n",
    "valid_dataloader = list(valid_iter)\n",
    "test_dataloader = list(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LSTMBinary(nn.Module):\n",
    "    def __init__(self, vocab_length, hidden_dim, emb_dim=300, num_lstm_layers=1, num_linear_layers=1):\n",
    "        super().__init__()\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "        self.num_linear_layers = num_linear_layers\n",
    "        self.embedding = nn.Embedding(vocab_length, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers = num_lstm_layers)\n",
    "        self.linear_layers = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, hidden_dim) for _ in range(num_linear_layers)]\n",
    "        )\n",
    "        self.output = nn.Linear(hidden_dim, 6)  # 6 different binary labels\n",
    "        self.tanh = nn.Tanh()\n",
    "            \n",
    "    def forward(self, seq):\n",
    "        emb = self.embedding(seq)\n",
    "        all_hidden, (h_n, c_n) = self.lstm(emb)\n",
    "        preds = h_n.squeeze()\n",
    "        for layer in self.linear_layers:\n",
    "            preds = self.tanh(layer(preds))\n",
    "        preds = self.output(preds)\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "model = LSTMBinary(vocab_length=len(TEXT.vocab), hidden_dim=500, emb_dim=100, num_linear_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [02:36<00:00,  1.98s/it]\n",
      "INFO:__main__:Epoch: 1, Training Loss: 0.5926, Validation Loss: 0.3726\n",
      "100%|██████████| 79/79 [02:22<00:00,  1.81s/it]\n",
      "INFO:__main__:Epoch: 2, Training Loss: 0.7229, Validation Loss: 0.3814\n",
      "100%|██████████| 79/79 [02:15<00:00,  1.72s/it]\n",
      "INFO:__main__:Epoch: 3, Training Loss: 0.6905, Validation Loss: 0.3912\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "epochs = 3\n",
    "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(train_dataloader):\n",
    "        x = batch.comment_text\n",
    "        y = torch.cat([getattr(batch, label).unsqueeze(1) for label in labels], dim=1).float()\n",
    "        opt.zero_grad()\n",
    "        predictions = model(x)\n",
    "        loss = loss_func(predictions, y)\n",
    "        loss.backward()\n",
    "        opt.step()     \n",
    "        running_loss += loss.data * x.size(0)\n",
    "    epoch_loss = running_loss / len(train)\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            x = batch.comment_text\n",
    "            y = torch.cat([getattr(batch, label).unsqueeze(1) for label in labels], dim=1).float()\n",
    "            predictions = model(x)\n",
    "            loss = loss_func(predictions, y)\n",
    "            valid_loss += loss.data * x.size(0)\n",
    "\n",
    "        valid_loss /= len(valid)\n",
    "    logger.info('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 40x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 22x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 24x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 8x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 146x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 270x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 14x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 315x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 54x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 60x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 25x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 32x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 624x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 10x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 105x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 35x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 165x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 21x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 34x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 75x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 11x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 26x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 5x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 27x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 7x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 123x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 110x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 100x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 30x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 6x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 14x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 20x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 9x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 129x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 92x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 55x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 18x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 39x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 178x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 13x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 78x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 52x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 47x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 64x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 69x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 16x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 58x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 154x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 9x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 84x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 49x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 50x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 116x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 31x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 399x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 19x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 195x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 72x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 17x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 37x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 36x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 44x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 96x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 33x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 12x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 81x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 28x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 16x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 66x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 62x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 45x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 88x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 986x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 139x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 8]\n",
       " \t[.comment_text]:[torch.LongTensor of size 2089x8]\n",
       " \t[.toxic]:[torch.LongTensor of size 8]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 8]\n",
       " \t[.obscene]:[torch.LongTensor of size 8]\n",
       " \t[.threat]:[torch.LongTensor of size 8]\n",
       " \t[.insult]:[torch.LongTensor of size 8]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 8],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 239x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 212x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 42x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64],\n",
       " \n",
       " [torchtext.data.batch.Batch of size 64]\n",
       " \t[.comment_text]:[torch.LongTensor of size 23x64]\n",
       " \t[.toxic]:[torch.LongTensor of size 64]\n",
       " \t[.severe_toxic]:[torch.LongTensor of size 64]\n",
       " \t[.obscene]:[torch.LongTensor of size 64]\n",
       " \t[.threat]:[torch.LongTensor of size 64]\n",
       " \t[.insult]:[torch.LongTensor of size 64]\n",
       " \t[.identity_hate]:[torch.LongTensor of size 64]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(train_iter)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[2].comment_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "best clans in <unk> \n",
      "\n",
      " 1 the <unk> - been the best clan in rs for 6 + years now \n",
      " 2 ' the ' clan \n",
      " 3 the british <unk> \n",
      " 4 damage inc. - an average clan .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "i m flattered , i truly am , i 've been here a couple of weeks and you consider me to be an established user . please do n't talk about me behind my back like little school children .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "canterbury \n",
      "\n",
      " why remove reference to <unk> as charge ? wiki 's own <unk> of canterbury has a depiction of the arms , which have historically been <unk> with the bishop 's own arms as his new personal <unk> .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "on sea world \n",
      "\n",
      " sorry mate , we 're working out the <unk> in the program .   its currently in v <unk> .   thanks for letting me know ! we 'll use this information to improve it .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      "  \" \" i am working on this page for school . \" \" wikipedia is not a free host . put it on one of your own websites or one of these wikis . — rhaworth    \"\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" short for the spanish word \" \" <unk> \" \" , which means rocket . defines an <unk> , <unk> and <unk> individual . \n",
      "\n",
      " born in july 16th 1980 , in <unk> city , central america . \"\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "i think this should go in the <unk> n ' <unk> section of <unk> . it is only <unk> that an article of this calibre be placed there . nonetheless , the accuracy of this article is quite <unk> .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      "\n",
      "  dispute resolution \n",
      "\n",
      " what dispute resolution you are talking about ? it is regarding a comment in wikipedia space , dispute resolution applies when the dispute is regarding article mainspace . ' ' '' ' '   \"\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      " i 'm being blocked for comments that i made months ago ?   and i was no more \" \" uncivil \" \" than several wikipedia admins - like , for example - regularly are .   \"\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "a redirect somewhere could n't hurt , though i still do n't think any o the candidates are ideal . but then if he passes the notability threshold some day the basic material is still there to work with .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "<unk> influences \n",
      "\n",
      " i have read somewhere ( alas forgotten source ) that the <unk> office was influenced by a room in the now italian <unk> residence in <unk> , ireland . does anybody know if this is true ?\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "where is the real vagina ? \n",
      "\n",
      " the real photo of vagina is gone ! \n",
      "\n",
      " would you mind if i make the new one ? \n",
      "\n",
      " the vagina picture is indonesian 's vagina . do you love it ?\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "editing on wikipedia <unk> something more that making lots of afds , voting delete in lots of afds , and deleting content here , there , and everywhere . i 've never encountered a more negative editor than you .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      " personal attacks \n",
      " what 's wikipedia 's policy on dealing with personal attacks ? i 've been dealing with them over at talk : planetary <unk> but they 're beginning to get on my nerves . podous \"\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "roma people in hungary : 8 - 10 % \n",
      "\n",
      " the <unk> social and economic situation of the roma , who account for between 8 and 10 percent of hungary 's 10 million people that means <unk> - 1,000,000 .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "cleanup \n",
      "\n",
      " i put the { { cleanup } } tag back on the page .   please do not remove it without reading the wikipedia : cleanup page first .    21:04 , 2004 aug 5 ( utc )\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "in addition , i am asking that you please stop accusing me of things i have nt done . i do not what what sock <unk> is and i think your taking this matter personally and abusing your power .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "smer - sd \n",
      "\n",
      " why is the <unk> party smer - sd between non - <unk> ? they are regular socialists . they used to be out of <unk> , but that was settled pretty long ago . liberal nationalist\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "sorry i left out the heading . it may be clearer now . btw , if you respond to me , leave me a talkback or i may never see it . ' ' '' ' ' ( talk )\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "maybe , but that does not lead to the conclusion that the <unk> aircraft remained in africa and did not return back after <unk> the soldiers . the article on <unk> also does not shed any light on this .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "barek , \n",
      "\n",
      " you are a retard , you <unk> ! ! ! \n",
      "\n",
      " blow me ! \n",
      "\n",
      " <unk> \n",
      "\n",
      " p.s. you were a mistake and take my account , i dont <unk> , and you dont care me !\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      "\n",
      "  aaron johnston ? \n",
      "\n",
      " was the aaron johnston who was on this show the same aaron johnston who is the son of lynn johnston of \" \" for better or for worse \" \" fame ? \n",
      "  \"\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "as i 've explained in the article , the noise is signal - <unk> , so <unk> for a system requires that you come up with a model of what that signal is going to look like first . —\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      " normally , i would leave it at an entry on the afd log page - in this case , another user expressed concern , considering the scope and popularity of the <unk> topic - ( t ) \"\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "everyone in southwest connecticut is a ny sports fan . boston sucks . we know better . we 're less than an hour from nyc and like 3 from boston . we 're not <unk> to our local teams .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      " american psychologist as additional resource \n",
      "\n",
      " i did not see listed in the references any citations of the \" \" american psychologist \" \" articles in january 2003 , some of which discuss this subject .    \"\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "whoa ... this article is wearing thin \n",
      "\n",
      " this needs to be reworded so that it sounds more concrete and it needs to be more organized instead of <unk> random facts at my face . can someone do that ?\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "the answer to that question has finally been found ; justin <unk> is one of the artists that does that song ; gap band nephew <unk> <unk> <unk> lyrics from early in the morning in the 2005 song signs .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "pov \n",
      " why is wikipedia deciding how many times he should have shot <unk> ? ?    why do n't you just stop being what you 're known for , wiki , bias .   just tell the facts .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "( utc ) \n",
      "\n",
      " this article was <unk> amusing and interesting .   i look forward to seeing it utterly destroyed so that it will conform to wikipedia 's quality standards . \n",
      "\n",
      " <unk>   <unk> , 24 november 2010\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "can you , or anyone , please tell me what 's going on ? email me or something , whatever it takes . this is ridiculous . i do n't care for games . + + : t / c\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "let 's try not to edit anything yet . unless they have confirmed that the operation has been proven successful then it is ok to add it on wikipedia , the rebels have been know to give unreliable information .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "<unk> <unk> \n",
      "\n",
      " i think the article is improved , more work to be done i 'm sure . you might want to read the history ( including the edit summaries ) as well as the article and talk pages\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "it 's a little bit too <unk> for my liking ( the first two <unk> , anyway ) , but i can live with it .   probably ought to have a prominent link to them somewhere , though .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "esoteric christianity \n",
      "\n",
      " i removed the reference to the jesus bloodline being linked to esoteric christians because it <unk> a source . the hyperlink to esoteric christianity shows that the wikipedia article did not refer to the jesus bloodline .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "section blanking by ip editors \n",
      "\n",
      " it appears as if one or two anonymous editors are repeatedly removing referenced content from this article without explanation . if this continues , perhaps an ip editing block should be set up .\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "and i do n't want to use it again . i do n't understand why <unk> insists on naccount . i could have wrote to him using any other account , maybe he would have kept it instead of naccount\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      " it was <unk> 's idea , but we all thought you deserved special mention - )   you 've really done a fine job , and reading your articles makes one proud .    ( talk ) \"\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "hi robert .. <unk> asked the author to give a proper copyright permission .. in the format as required by wikipedia . will get it in a couple of days and send it across to the relevant authorities ... <unk>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "thank you for your note . given the risk to you if you do restore copyright problems to an article , i felt it rather urgent enough to reply at your talk page . : )   ( talk )\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "<unk> ... \n",
      "\n",
      " chris loves you . i tried the ' <unk> ' and ' <unk> ' and a random mexican answered the phone ... <unk> , i 'm gon na send flowers . do n't freak out . <unk>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" . as it currently seems to be only a push by unknown musicians and labels for their own special interest , <unk> the \" \" hype \" \" driven by the likes of <unk> and the like etc \"\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "more fuel \n",
      "\n",
      " just drop that 5 millions of manga volumes sold . \n",
      " to be more precise the news say 500 ( ten - thousands ) and yes google translation will display 500 millions which is absurd ;) <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "talk pages are also where some of us have to try and get uninformed idiots to back down so we can make changes . it 's hard to have an impact on an article such as <unk> <unk> . <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "vandalism \n",
      "\n",
      " mongo removed all of the tags i placed about problems with the article . \n",
      " http://en.wikipedia.org/w/index.php?title=chad_kellogg&diff;=603899892&oldid;=603899206 \n",
      " the tags specify that they should remain until the problems are resolved .   potential vandalism again . \n",
      " http://en.wikipedia.org/w/index.php?title=chad_kellogg&diff;=603899892&oldid;=603899206 <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      "\n",
      "  aug 10 2010   death hoax currently <unk> \n",
      "\n",
      " <unk> is currently trying to get \" \" <unk> <unk> dead at 56 \" \" to the top of google trends .   monitor article closely . \" <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      "\n",
      "  deletion probable \n",
      "\n",
      " i 'm not aware that \" \" divine spark \" \" is a theological term of art ; if it is n't , then the article should probably be deleted .   tc \" <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      "\n",
      "  context of \" \" in the beginning \" \" ? \n",
      "\n",
      " the article starts in media <unk> . what was \" \" the <unk> committee \" \" . at the very least a link ?    \" <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      "\n",
      "  123 <unk> , july 18 , 2005 ( utc ) \n",
      "\n",
      " p.s. feel free to leave a message on my talk page if you need help with anything or simply wish to say hello . ) \" <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      "\n",
      "  the battle of the bulge \n",
      "\n",
      "  as the german offensive <unk> east to west creating the nose - like bulge shape ( <unk> ) between the 16th and 26th of december , <unk> . ] ] \" <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      " wp : or does n't even come close to applying . the definition of \" \" <unk> \" \" is not or , nor is the picture we have of his release form . <unk>   \" <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "forget it . if inaccuracy is what wikipedia aims for , then go ahead and leave it <unk> . but just for the sake of properly informing people , look at this : <unk> put that in the cite <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" = = <unk> \n",
      " do n't take the template out of the sandbox . it says \" \" do n't remove \" \" for a reason .   <unk> , 10 jan 2005 ( utc ) \n",
      "\n",
      " \" <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "you forgot to mention all the civilians killed by american bombs in indochina , we started the ball rolling and <unk> pot finished the job , its a real mean world , not all <unk> and flowers pal . <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "you should certainly contact your local police and file a report . make sure to show documentation demonstration the lack of response from the wmf . their lack of response may be <unk> <unk> in some jurisdictions . <unk> <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" : : issue has been resolved <unk> by the non - wikipedia editor \" \" <unk> \" \" . thanks for having made the enquiry with <unk> and for having been constructive in your approach .   \n",
      "\n",
      " \" <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "stop it ! ! ! ! ! ! ! ! ! ! \n",
      "\n",
      " stop deleting stuff i am fixing i was not done fixing the spring valley high school page ! ! ! ! ! ! ! ! ! <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "you 're welcome . some of my work was also quoted in the <unk> book , but they were all correctly acknowledged and footnoted and thus not among the errors and corrections noted in the researchers ' paper . <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "please stop your disruptive editing . if your vandalism continues , you will be blocked from editing wikipedia . \n",
      "  please stop your disruptive editing . if your vandalism continues , you will be blocked from editing wikipedia . <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "please stop adding an endless series of pointless tags to pages i have edited . your conduct is now effectively stalking . as soon as the tags are dealt with , you just add other ones . thanks . <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "there are restrictions on primary documents ; they can only be used for facts . if you have a site that you can upload to , fine . otherwise you can try wikisource and then link from there . <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "the new royal house in denmark \n",
      "\n",
      " what will it be called ?   how do the <unk> feel about a french dynasty ?   are they jealous that the uk has their old one ?   lmao . <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      " \" \" circular \" \" as well as the counter arguments . defending s - c is risen to the level of religion . it 's not only circular , it 's <unk> . <unk>   \" <pad>\n",
      "\n",
      " NEW SENTENCE \n",
      "\n",
      "\" \n",
      "\n",
      "  please do not vandalize pages , as you did with this edit to victoria ( australia ) . if you continue to do so , you will be blocked from editing .   ~ talk contribs \" <pad>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(l[0].comment_text[1])):\n",
    "    print(\"\\n NEW SENTENCE \\n\")\n",
    "    print(' '.join([TEXT.vocab.itos[x] for x in l[0].comment_text[:,i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
